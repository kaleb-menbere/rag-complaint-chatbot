{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9238307d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Task 1: Exploratory Data Analysis and Data Preprocessing\n",
    "# \n",
    "# ## Objective\n",
    "# Understand the structure, content, and quality of the complaint data and prepare it for the RAG pipeline.\n",
    "\n",
    "# %%\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import re\n",
    "from collections import Counter\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "# %%\n",
    "# Load the full CFPB complaint dataset\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('../data/raw/complaints.csv', low_memory=False)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "# %%\n",
    "# Initial EDA - Display basic info\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "# %%\n",
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "display(missing_df[missing_df['Missing Values'] > 0].sort_values('Percentage', ascending=False))\n",
    "\n",
    "# %%\n",
    "# Analyze the distribution of complaints across different Products\n",
    "print(\"Product distribution:\")\n",
    "product_counts = df['Product'].value_counts()\n",
    "product_percentages = (product_counts / len(df)) * 100\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar chart\n",
    "ax1.bar(range(len(product_counts[:10])), product_counts.values[:10])\n",
    "ax1.set_xlabel('Product')\n",
    "ax1.set_ylabel('Number of Complaints')\n",
    "ax1.set_title('Top 10 Products by Complaint Count')\n",
    "ax1.set_xticks(range(len(product_counts[:10])))\n",
    "ax1.set_xticklabels(product_counts.index[:10], rotation=45, ha='right')\n",
    "\n",
    "# Pie chart for top 10\n",
    "ax2.pie(product_counts.values[:10], labels=product_counts.index[:10], autopct='%1.1f%%')\n",
    "ax2.set_title('Product Distribution (Top 10)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Filter for our five specified products\n",
    "target_products = [\n",
    "    'Credit card',\n",
    "    'Credit card or prepaid card',\n",
    "    'Credit reporting',\n",
    "    'Debt collection',\n",
    "    'Money transfer, virtual currency, or money service',\n",
    "    'Virtual currency'\n",
    "]\n",
    "\n",
    "# Let's see what products we actually have\n",
    "print(\"All unique products in dataset:\")\n",
    "for product in df['Product'].unique():\n",
    "    print(f\"  - {product}\")\n",
    "\n",
    "# %%\n",
    "# Based on the dataset, let's identify the correct product names\n",
    "# Looking at typical CFPB dataset, we need to map to our requirements\n",
    "product_mapping = {\n",
    "    'Credit card': ['Credit card', 'Credit card or prepaid card'],\n",
    "    'Personal loan': ['Payday loan', 'Student loan', 'Vehicle loan or lease'],\n",
    "    'Savings account': ['Bank account or service', 'Checking or savings account'],\n",
    "    'Money transfer': ['Money transfer, virtual currency, or money service', 'Virtual currency']\n",
    "}\n",
    "\n",
    "# Let's check what we have\n",
    "all_products = []\n",
    "for category, products in product_mapping.items():\n",
    "    for product in products:\n",
    "        if product in df['Product'].unique():\n",
    "            all_products.extend(products)\n",
    "            break\n",
    "\n",
    "# %%\n",
    "# Calculate and visualize the length of Consumer complaint narrative\n",
    "print(\"Analyzing complaint narrative length...\")\n",
    "\n",
    "# Check if we have the narrative column\n",
    "if 'Consumer complaint narrative' in df.columns:\n",
    "    # Calculate word count for each narrative\n",
    "    df['narrative_word_count'] = df['Consumer complaint narrative'].fillna('').apply(lambda x: len(str(x).split()))\n",
    "    \n",
    "    # Create histogram of narrative lengths\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Histogram\n",
    "    ax1.hist(df['narrative_word_count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax1.set_xlabel('Word Count')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Distribution of Complaint Narrative Length')\n",
    "    ax1.axvline(df['narrative_word_count'].median(), color='red', linestyle='--', label=f'Median: {df[\"narrative_word_count\"].median():.0f}')\n",
    "    ax1.axvline(df['narrative_word_count'].mean(), color='green', linestyle='--', label=f'Mean: {df[\"narrative_word_count\"].mean():.0f}')\n",
    "    ax1.legend()\n",
    "    ax1.set_xlim(0, 1000)  # Limit x-axis for better visualization\n",
    "    \n",
    "    # Box plot\n",
    "    ax2.boxplot(df['narrative_word_count'].dropna())\n",
    "    ax2.set_ylabel('Word Count')\n",
    "    ax2.set_title('Box Plot of Narrative Length')\n",
    "    ax2.set_xticklabels(['Narratives'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print statistics\n",
    "    print(\"Narrative Length Statistics:\")\n",
    "    print(f\"  Mean: {df['narrative_word_count'].mean():.2f}\")\n",
    "    print(f\"  Median: {df['narrative_word_count'].median():.2f}\")\n",
    "    print(f\"  Std: {df['narrative_word_count'].std():.2f}\")\n",
    "    print(f\"  Min: {df['narrative_word_count'].min():.2f}\")\n",
    "    print(f\"  Max: {df['narrative_word_count'].max():.2f}\")\n",
    "    \n",
    "    # Count narratives with different lengths\n",
    "    print(\"\\nNarrative Length Categories:\")\n",
    "    print(f\"  Empty narratives: {len(df[df['Consumer complaint narrative'].isna()])}\")\n",
    "    print(f\"  Very short (1-10 words): {len(df[(df['narrative_word_count'] > 0) & (df['narrative_word_count'] <= 10)])}\")\n",
    "    print(f\"  Short (11-50 words): {len(df[(df['narrative_word_count'] > 10) & (df['narrative_word_count'] <= 50)])}\")\n",
    "    print(f\"  Medium (51-200 words): {len(df[(df['narrative_word_count'] > 50) & (df['narrative_word_count'] <= 200)])}\")\n",
    "    print(f\"  Long (201-500 words): {len(df[(df['narrative_word_count'] > 200) & (df['narrative_word_count'] <= 500)])}\")\n",
    "    print(f\"  Very long (>500 words): {len(df[df['narrative_word_count'] > 500])}\")\n",
    "\n",
    "# %%\n",
    "# Identify the number of complaints with and without narratives\n",
    "if 'Consumer complaint narrative' in df.columns:\n",
    "    has_narrative = df['Consumer complaint narrative'].notna() & (df['Consumer complaint narrative'].str.strip() != '')\n",
    "    print(\"Complaints with narratives:\")\n",
    "    print(f\"  With narrative: {has_narrative.sum()} ({has_narrative.mean()*100:.2f}%)\")\n",
    "    print(f\"  Without narrative: {(~has_narrative).sum()} ({((~has_narrative).mean()*100):.2f}%)\")\n",
    "    \n",
    "    # Visualize\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    has_narrative.value_counts().plot(kind='pie', autopct='%1.1f%%', \n",
    "                                      labels=['Without Narrative', 'With Narrative'],\n",
    "                                      colors=['#ff9999', '#66b3ff'])\n",
    "    plt.title('Complaints With vs Without Narratives')\n",
    "    plt.ylabel('')\n",
    "    plt.show()\n",
    "\n",
    "# %%\n",
    "# Filter the dataset to meet project requirements\n",
    "print(\"Filtering dataset...\")\n",
    "\n",
    "# First, let's see what columns we have\n",
    "print(\"Available columns:\", df.columns.tolist())\n",
    "\n",
    "# Based on typical CFPB dataset structure\n",
    "# We'll create a function to map to our required categories\n",
    "def map_to_target_category(product):\n",
    "    product = str(product).lower()\n",
    "    \n",
    "    if any(keyword in product for keyword in ['credit card', 'prepaid card']):\n",
    "        return 'Credit Cards'\n",
    "    elif any(keyword in product for keyword in ['loan', 'mortgage']):\n",
    "        return 'Personal Loans'\n",
    "    elif any(keyword in product for keyword in ['savings', 'checking', 'bank account', 'deposit']):\n",
    "        return 'Savings Accounts'\n",
    "    elif any(keyword in product for keyword in ['money transfer', 'money service', 'virtual currency', 'wire transfer']):\n",
    "        return 'Money Transfers'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Apply mapping\n",
    "df['product_category'] = df['Product'].apply(map_to_target_category)\n",
    "\n",
    "# Check distribution\n",
    "print(\"Mapped product categories distribution:\")\n",
    "category_counts = df['product_category'].value_counts()\n",
    "display(category_counts)\n",
    "\n",
    "# %%\n",
    "# Filter for our four target categories\n",
    "target_categories = ['Credit Cards', 'Personal Loans', 'Savings Accounts', 'Money Transfers']\n",
    "filtered_df = df[df['product_category'].isin(target_categories)].copy()\n",
    "print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
    "print(f\"Original dataset shape: {df.shape}\")\n",
    "print(f\"Percentage kept: {len(filtered_df)/len(df)*100:.2f}%\")\n",
    "\n",
    "# %%\n",
    "# Remove records with empty narratives\n",
    "if 'Consumer complaint narrative' in filtered_df.columns:\n",
    "    initial_count = len(filtered_df)\n",
    "    filtered_df = filtered_df[\n",
    "        filtered_df['Consumer complaint narrative'].notna() & \n",
    "        (filtered_df['Consumer complaint narrative'].str.strip() != '')\n",
    "    ].copy()\n",
    "    print(f\"Removed {initial_count - len(filtered_df)} records with empty narratives\")\n",
    "    print(f\"Final filtered dataset shape: {filtered_df.shape}\")\n",
    "\n",
    "# %%\n",
    "# Text cleaning function\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean the text narratives to improve embedding quality\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove excessive whitespace\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    # Remove common boilerplate text patterns\n",
    "    boilerplate_patterns = [\n",
    "        r'i am writing to file a complaint',\n",
    "        r'to whom it may concern',\n",
    "        r'dear sir/madam',\n",
    "        r'this is a complaint regarding',\n",
    "        r'please be advised that',\n",
    "        r'i am writing to express my dissatisfaction',\n",
    "        r'i would like to file a complaint',\n",
    "        r'complaint id:',\n",
    "        r'reference number:',\n",
    "        r'case number:',\n",
    "    ]\n",
    "    \n",
    "    for pattern in boilerplate_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove special characters but keep basic punctuation\n",
    "    text = re.sub(r'[^\\w\\s.,!?]', ' ', text)\n",
    "    \n",
    "    # Remove multiple spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remove leading/trailing whitespace\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# %%\n",
    "# Apply text cleaning\n",
    "print(\"Cleaning text narratives...\")\n",
    "filtered_df['cleaned_narrative'] = filtered_df['Consumer complaint narrative'].apply(clean_text)\n",
    "\n",
    "# Check cleaning results\n",
    "print(\"\\nSample before cleaning:\")\n",
    "sample_idx = filtered_df.index[0]\n",
    "print(filtered_df.loc[sample_idx, 'Consumer complaint narrative'][:500])\n",
    "print(\"\\nSample after cleaning:\")\n",
    "print(filtered_df.loc[sample_idx, 'cleaned_narrative'][:500])\n",
    "\n",
    "# %%\n",
    "# Check word count distribution after cleaning\n",
    "filtered_df['cleaned_word_count'] = filtered_df['cleaned_narrative'].apply(lambda x: len(x.split()))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(filtered_df['cleaned_word_count'], bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Word Count (Cleaned)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Cleaned Narrative Length')\n",
    "plt.axvline(filtered_df['cleaned_word_count'].median(), color='red', linestyle='--', \n",
    "           label=f'Median: {filtered_df[\"cleaned_word_count\"].median():.0f}')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "category_means = filtered_df.groupby('product_category')['cleaned_word_count'].mean()\n",
    "category_means.plot(kind='bar')\n",
    "plt.xlabel('Product Category')\n",
    "plt.ylabel('Average Word Count')\n",
    "plt.title('Average Narrative Length by Category')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# Save the cleaned and filtered dataset\n",
    "output_path = 'data/processed/filtered_complaints.csv'\n",
    "filtered_df.to_csv(output_path, index=False)\n",
    "print(f\"Saved filtered dataset to: {output_path}\")\n",
    "print(f\"Final dataset size: {len(filtered_df)} complaints\")\n",
    "\n",
    "# %%\n",
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL DATASET SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total complaints: {len(filtered_df)}\")\n",
    "print(\"\\nComplaints by product category:\")\n",
    "for category, count in filtered_df['product_category'].value_counts().items():\n",
    "    percentage = (count / len(filtered_df)) * 100\n",
    "    print(f\"  {category}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\nAverage word count per narrative: {filtered_df['cleaned_word_count'].mean():.1f}\")\n",
    "print(f\"Median word count: {filtered_df['cleaned_word_count'].median():.1f}\")\n",
    "print(f\"Date range: {filtered_df['Date received'].min()} to {filtered_df['Date received'].max()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicate_narratives = filtered_df['cleaned_narrative'].duplicated().sum()\n",
    "print(f\"\\nDuplicate narratives: {duplicate_narratives} ({duplicate_narratives/len(filtered_df)*100:.2f}%)\")\n",
    "\n",
    "# %%\n",
    "# Additional analysis: Most common issues by category\n",
    "print(\"\\nMost common issues by product category:\")\n",
    "for category in target_categories:\n",
    "    category_data = filtered_df[filtered_df['product_category'] == category]\n",
    "    if 'Issue' in category_data.columns:\n",
    "        top_issues = category_data['Issue'].value_counts().head(5)\n",
    "        print(f\"\\n{category}:\")\n",
    "        for issue, count in top_issues.items():\n",
    "            print(f\"  - {issue}: {count}\")\n",
    "\n",
    "# %%\n",
    "# Save a sample for quick testing\n",
    "sample_df = filtered_df.sample(min(1000, len(filtered_df)), random_state=42)\n",
    "sample_path = 'data/processed/sample_complaints.csv'\n",
    "sample_df.to_csv(sample_path, index=False)\n",
    "print(f\"\\nSaved sample dataset to: {sample_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd022048",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
